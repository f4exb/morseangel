{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with noisy envelope - using dataset and data loader\n",
    "\n",
    "Same flow as in `RNN-Morse-feature` but uses a data loader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sounddevice torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install libportaudio2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate annotated raw signal\n",
    "\n",
    "Generates the envelope after audio preprocessing. The resulting decimation factor is 128 thus we will take 1 every 128 samples from the original signal modulated at 8 kHz sample rate. This uses a modified version of `encode_df` (`encode_df_decim`) of `MorseGen` thus the original ratio in samples per dit is respected. This effectively takes a floating point ratio (shown in display) for the samples per dit decimation (about 5.77 for the nominal values of 8 kHz sampling rate and 13 WPM Morse code speed) \n",
    "\n",
    "The SNR must be calculated in the FFT bin bandwidth. In the original `RNN-Morse-pytorch` notebook the bandwidth is 4 kHz / 256 = 15,625 Hz and SNR is 3 dB. Theoretically you would apply the FFT ratio to the original SNR but this does not work in practice. You have to take a much lower SNR to obtain a similar envelope.\n",
    "\n",
    "### Base functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "def random_partition(k, iterable):\n",
    "    results = [[] for i in range(k)]\n",
    "    for value in iterable:\n",
    "        x = random.randrange(k)\n",
    "        results[x].append(value)\n",
    "    return results\n",
    "\n",
    "def random_strings(k, rawchars):\n",
    "    results = [\"\" for i in range(k)]\n",
    "    for c in rawchars:\n",
    "        x = random.randrange(k)\n",
    "        results[x] += c\n",
    "    return results\n",
    "\n",
    "def get_morse_str(nchars=132, nwords=27):\n",
    "    np.random.seed(0)\n",
    "    rawchars = ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(nchars))\n",
    "    words = random_strings(nwords, rawchars)\n",
    "    morsestr = ' '.join(words)\n",
    "    return morsestr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morsestr = get_morse_str()\n",
    "print(len(morsestr), morsestr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signal and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MorseGen\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "def get_new_data(SNR_dB=-23, nchars=132, nwords=27, phrase=None):\n",
    "    if not phrase:\n",
    "        phrase = MorseGen.get_morse_str(nchars=nchars, nwords=nwords)\n",
    "    print(len(phrase), phrase)\n",
    "    Fs = 8000\n",
    "    morse_gen = MorseGen.Morse()\n",
    "    samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "    n_prev = int((samples_per_dit/128)*12) + 1 # number of samples to look back is slightly more than a dit-dah and a word space (2+3+7=12)\n",
    "    print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "    label_df = morse_gen.encode_df_decim(phrase, samples_per_dit, 128)\n",
    "    # keep the envelope\n",
    "    label_df_env = label_df.drop(columns=['dit','dah', 'ele', 'chr', 'wrd'])\n",
    "    # remove the envelope\n",
    "    label_df.drop(columns=['env'], inplace=True)\n",
    "    SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "    SNR_linear *= 256 # Apply original FFT\n",
    "    print(f'Resulting SNR for original {SNR_dB} dB is {(10.0 * np.log10(SNR_linear)):.2f} dB')\n",
    "    t = np.linspace(0, len(label_df_env)-1, len(label_df_env))\n",
    "    morsecode = label_df_env.env\n",
    "    power = np.sum(morsecode**2)/len(morsecode)\n",
    "    noise_power = power/SNR_linear\n",
    "    noise = np.sqrt(noise_power)*np.random.normal(0, 1, len(morsecode))\n",
    "    # noise = butter_lowpass_filter(raw_noise, 0.9, 3) # Noise is also filtered in the original setup from audio. This empirically simulates it\n",
    "    signal = morsecode + noise\n",
    "    return signal, label_df, n_prev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try it ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, label_df, n_prev = get_new_data(-17)\n",
    "\n",
    "# Show\n",
    "print(n_prev)\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "    \n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0:x1]*0.5, label=\"sig\")\n",
    "plt.plot(label_df[x0:x1].dit*0.9 + 1.0, label='dit')\n",
    "plt.plot(label_df[x0:x1].dah*0.9 + 2.0, label='dah')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 3.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 4.0, label='chr')\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 5.0, label='wrd')\n",
    "plt.title(\"signal and labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data loader\n",
    "### Define dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class MorsekeyingDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, device, SNR_dB=-23, nchars=132, nwords=27, phrase=None):\n",
    "        self.signal, self.label_df, self.seq_len = get_new_data(SNR_dB, nchars, nwords, phrase)\n",
    "        self.X = torch.FloatTensor(self.signal.values).to(device)\n",
    "        self.y = torch.FloatTensor(self.label_df.values).to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.__len__() - self.seq_len\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index:index+self.seq_len], self.y[index+self.seq_len])\n",
    "    \n",
    "    def get_signal(self):\n",
    "        return self.signal\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return self.label_df\n",
    "    \n",
    "    def get_seq_len(self):\n",
    "        return self.seq_len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_dataset = MorsekeyingDataset(device, -25, 132*2, 27*2)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = train_dataset.get_signal()\n",
    "label_df = train_dataset.get_labels()\n",
    "\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "\n",
    "x0 = 0\n",
    "x1 = 1500\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0:x1]*0.5, label=\"sig\")\n",
    "plt.plot(label_df[x0:x1].dit*0.9 + 1.0, label='dit')\n",
    "plt.plot(label_df[x0:x1].dah*0.9 + 2.0, label='dah')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 3.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 4.0, label='chr')\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 5.0, label='wrd')\n",
    "plt.title(\"signal and labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "\n",
    "Let's create the model now so we have an idea of its inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MorseEnvLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "    \n",
    "class MorseEnvBatchedLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "        self.m = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        #print(len(input_seq), input_seq.shape, input_seq.view(-1, 1, 1).shape)\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(-1, 1, 1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return self.m(predictions[-1])\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )     \n",
    "    \n",
    "class MorseEnvLSTM2(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM stack\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=2, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(2, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(2, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "        \n",
    "class MorseEnvNoHLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Do not keep hidden cell\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1), (h0, c0))\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "class MorseEnvBiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Attempt Bidirectional LSTM: does not work\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_size=12, num_layers=1, num_classes=6):\n",
    "        super(MorseEnvBiLSTM, self).__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x.view(len(x), 1, -1), (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model instance and print the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers:\n",
    "# 4: good at reconstructing signal, some post-processing necessary for dit/dah, word silence is weak and undistinguishable from character silence \n",
    "# 5: fairly good at reconstructing signal, but word space sense is lost\n",
    "# 6: more contrast on all signals and word space sense is good but a spike appears in the silence in predicted envelope\n",
    "morse_env_model = MorseEnvBatchedLSTM(device, hidden_layer_size=7, output_size=5).to(device) # This is the only way to get things work properly with device\n",
    "morse_env_loss_function = nn.MSELoss()\n",
    "morse_env_optimizer = torch.optim.Adam(morse_env_model.parameters(), lr=0.001)\n",
    "\n",
    "print(morse_env_model)\n",
    "print(morse_env_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu\n",
    "for m in morse_env_model.parameters():\n",
    "    print(m.shape, m.device)\n",
    "X_t = torch.rand(n_prev)\n",
    "#X_t = torch.tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341, -1.0000, -0.9385])\n",
    "X_t = X_t.cuda()\n",
    "print(X_t)\n",
    "morse_env_model(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "channels=10\n",
    "H=n_prev\n",
    "W=1\n",
    "torchinfo.summary(morse_env_model, input_size=(channels, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_loader)\n",
    "X, y = next(it)\n",
    "print(X.reshape(70,1).shape, X[0].shape, y[0].shape)\n",
    "print(X[0], y[0])\n",
    "X, y = next(it)\n",
    "print(X[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 30\n",
    "morse_env_model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    train_losses = []\n",
    "    for j, train in enumerate(train_loader):\n",
    "        X_train = train[0][0]\n",
    "        y_train = train[1][0]\n",
    "        morse_env_optimizer.zero_grad()\n",
    "        if morse_env_model.__class__.__name__ in [\"MorseEnvLSTM\", \"MorseEnvLSTM2\", \"MorseEnvBatchedLSTM\"]:\n",
    "            morse_env_model.zero_hidden_cell() # this model needs to reset the hidden cell\n",
    "        y_pred = morse_env_model(X_train)\n",
    "        single_loss = morse_env_loss_function(y_pred, y_train)\n",
    "        single_loss.backward()\n",
    "        morse_env_optimizer.step()\n",
    "        train_losses.append(single_loss.item())\n",
    "        if j % 1000 == 0:\n",
    "            train_loss = np.mean(train_losses)\n",
    "            train_std = np.std(train_losses)\n",
    "            print(f'   train {j}/{len(train_loader)} loss: {train_loss:6.4f} std: {train_std:6.4f}')\n",
    "    train_loss = np.mean(train_losses)\n",
    "    print(f'epoch: {i+1:3} loss: {train_loss:6.4f} std: {train_std:6.4f}')\n",
    "\n",
    "print(f'final: {i+1:3} epochs loss: {train_loss:6.4f} std: {train_std:6.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(morse_env_model.state_dict(), 'models/morse_env_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_phrase = \"VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB VVV DE F4EXB\"\n",
    "test_dataset = MorsekeyingDataset(device, -24, 132, 27, new_phrase)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False) # Batch size must be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = test_dataset.get_signal()\n",
    "label_df = test_dataset.get_labels()\n",
    "\n",
    "print(type(signal), signal.shape)\n",
    "print(type(label_df), label_df.shape)\n",
    "\n",
    "x0 = 0\n",
    "x1 = 3000\n",
    "\n",
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(signal[x0:x1]*0.5, label=\"sig\")\n",
    "plt.plot(label_df[x0:x1].dit*0.9 + 1.0, label='dit')\n",
    "plt.plot(label_df[x0:x1].dah*0.9 + 2.0, label='dah')\n",
    "plt.plot(label_df[x0:x1].ele*0.9 + 3.0, label='ele')\n",
    "plt.plot(label_df[x0:x1].chr*0.9 + 4.0, label='chr')\n",
    "plt.plot(label_df[x0:x1].wrd*0.9 + 5.0, label='wrd')\n",
    "plt.title(\"signal and labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_dit_l = []\n",
    "p_dah_l = []\n",
    "p_ele_l = []\n",
    "p_chr_l = []\n",
    "p_wrd_l = []\n",
    "y_test_a = []\n",
    "morse_env_model.eval()\n",
    "\n",
    "for X_test0, y_test0 in test_loader:\n",
    "    X_test = X_test0[0]\n",
    "    pred_val = morse_env_model(X_test).cpu()\n",
    "    p_dit_l.append(pred_val[0].item())\n",
    "    p_dah_l.append(pred_val[1].item())\n",
    "    p_ele_l.append(pred_val[2].item())\n",
    "    p_chr_l.append(pred_val[3].item())\n",
    "    p_wrd_l.append(pred_val[4].item())\n",
    "    y_test_a.append(y_test0[0,0] + y_test0[0,1])\n",
    "        \n",
    "p_dit = np.array(p_dit_l)\n",
    "p_dah = np.array(p_dah_l)\n",
    "p_ele = np.array(p_ele_l)\n",
    "p_chr = np.array(p_chr_l)\n",
    "p_wrd = np.array(p_wrd_l)\n",
    "y_test_v = np.array(y_test_a)\n",
    "\n",
    "# trim negative values\n",
    "p_dit[p_dit < 0] = 0\n",
    "p_dah[p_dah < 0] = 0\n",
    "p_ele[p_ele < 0] = 0\n",
    "p_chr[p_chr < 0] = 0\n",
    "p_wrd[p_wrd < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(y_test_v[:x1]*0.9, label=\"y\")\n",
    "plt.plot(p_dit[:x1]*0.9 + 1.0, label=\"dit\")\n",
    "plt.plot(p_dah[:x1]*0.9 + 2.0, label=\"dah\")\n",
    "plt.plot(p_ele[:x1]*0.9 + 3.0, label=\"ele\")\n",
    "plt.plot(p_chr[:x1]*0.9 + 4.0, label=\"chr\")\n",
    "plt.plot(p_wrd[:x1]*0.9 + 5.0, label=\"wrd\")\n",
    "plt.title(\"Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('img/pred.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_test = signal[n_prev:].to_numpy()\n",
    "sig = p_dit[:x1] + p_dah[:x1]\n",
    "sig = (sig - min(sig)) / (max(sig) - min(sig))\n",
    "mor = y_test_v[:x1]\n",
    "plt.figure(figsize=(30,3))\n",
    "plt.plot(sig, label=\"mod\")\n",
    "plt.plot(l_test[:x1] + 1.0, label=\"sig\")\n",
    "plt.plot(mor*2.2, label=\"mor\", linestyle='--')\n",
    "plt.title(\"reconstructed signal modulation with 'dah' and 'dit'\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,4))\n",
    "plt.plot(p_dit[:x1], label='dit')\n",
    "plt.plot(p_dah[:x1], label='dah')\n",
    "plt.plot(mor*0.5 + 1.0, label='mor')\n",
    "plt.title(\"'dit' and 'dah' symbols prediction vs modulation\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(p_ele[:x1], label='ele')\n",
    "plt.plot(mor, label='mor')\n",
    "plt.title(\"Element space prediction vs modulation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(p_chr[:x1] ,label='chr')\n",
    "plt.plot(mor, label='mor')\n",
    "plt.title(\"Character space prediction vs modulation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(p_wrd[:x1], label='wrd')\n",
    "plt.plot(mor, label='mor')\n",
    "plt.title(\"Word space prediction vs modulation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p_sig = 1.0 - (p_ele + p_chr + p_wrd)\n",
    "p_sig = p_dit + p_dah\n",
    "p_ditd = p_dit - p_dah\n",
    "p_dahd = p_dah - p_dit\n",
    "plt.figure(figsize=(50,8))\n",
    "plt.plot(l_test[:x1]*0.9, label=\"inp\")\n",
    "plt.plot(p_sig[:x1]*0.9 + 1.0, label=\"sig\")\n",
    "plt.plot(p_dit[:x1]*0.9 + 2.0, label=\"dit\")\n",
    "plt.plot(p_dah[:x1]*0.9 + 3.0, label=\"dah\")\n",
    "plt.plot(p_ele[:x1]*0.9 + 4.0, label=\"ele\")\n",
    "plt.plot(p_chr[:x1]*0.9 + 5.0, label=\"chr\")\n",
    "plt.plot(p_wrd[:x1]*0.9 + 6.0, label=\"wrd\")\n",
    "plt.plot(mor*7.2, label=\"mor\")\n",
    "plt.title(\"Altogether vs signal and modulation\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.figure(figsize=(50,4))\n",
    "plt.plot(p_dit[:x1]*0.9 + 0.0, label=\"dit\")\n",
    "plt.plot(p_dahd[:x1]*0.9 + 1.0, label=\"dahd\")\n",
    "plt.plot(p_ele[:x1]*0.9 + 2.0, label=\"ele\")\n",
    "plt.plot(mor*3.2, label=\"mor\")\n",
    "plt.title(\"Differential dah\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.special\n",
    "from scipy.io import wavfile\n",
    "\n",
    "Fcode = 600\n",
    "Fs = 8000\n",
    "noverlap = 128\n",
    "decim = 128\n",
    "emod = np.array([sp.special.expit(8*(0.9*x-0.5)) for x in sig])\n",
    "#emod = sig\n",
    "emod /= max(emod)\n",
    "remod = np.array([[x]*noverlap for x in emod]).flatten()\n",
    "wt = (Fcode / Fs)*2*np.pi\n",
    "tone = np.sin(np.arange(len(remod))*wt)\n",
    "wavfile.write('audio/re.wav', Fs, tone*remod)\n",
    "ref_mod = np.array([[x]*decim for x in mor]).flatten()\n",
    "plt.figure(figsize=(50,5))\n",
    "plt.plot(tone*remod)\n",
    "plt.plot(ref_mod*1.2, label='mor')\n",
    "plt.title(\"reconstructed signal\")\n",
    "plt.grid()\n",
    "# .4QTV4PB EZ1 JBGJ TT1W4M...\n",
    "# 7U7K 0DC55B H ZN0J Q9 H2X0 LZ16A ECA2DE 6A2 NUPU 67IL6EIH YVZA 5OTGC3U C3R PGW RS0 84QTV4PB EZ1 JBGJ TT1W4M5PBJ GZVLWXQG 7POU6 FMTXA N3CZ Y1Q9VZ6 9TVL CWP8KSB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omod = l_test[:x1]\n",
    "orig_mod = np.array([[x]*decim for x in omod]).flatten()\n",
    "orig_mod /= max(orig_mod)\n",
    "orig_mod *= 1.5\n",
    "wavfile.write('audio/or.wav', Fs, tone*orig_mod)\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.plot(tone*orig_mod)\n",
    "plt.plot(ref_mod*1.2, label='mor')\n",
    "plt.title(\"original filtered signal\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "sx = np.linspace(0, 1, 121)\n",
    "sy = sp.special.expit(8*(0.8*sx-0.5))\n",
    "plt.plot(sx, sy)\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.title('expit(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
