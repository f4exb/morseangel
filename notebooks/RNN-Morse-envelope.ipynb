{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with noisy envelope\n",
    "\n",
    "Same flow as in `RNN-Morse-pytorch` but uses directly the envelope as the input time series. It is assumed that the preprocessing has been done to obtain this envelope. SNR is calculated based on the average power of the envelope signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sounddevice torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install libportaudio2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate annotated raw signal\n",
    "\n",
    "Generates the envelope after audio preprocessing. The resulting decimation factor is 128 thus we will take 1 every 128 samples from the original signal modulated at 8 kHz sample rate. This uses a modified version of `encode_df` (`encode_df_decim`) of `MorseGen` thus the original ratio in samples per dit is respected. This effectively takes a floating point ratio (shown in display) for the samples per dit decimation (about 5.77 for the nominal values of 8 kHz sampling rate and 13 WPM Morse code speed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MorseGen\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#phrase = '01234 6789 QUICK BROWN FOX 01234 6789 QUICK BROWN FOX01234 6789 QUICK BROWN FOX01234 6789 QUICK BROWN FOX01234 6789 QUICK BROWN FOX 01234 6789 QUICK BROWN FOX'\n",
    "#phrase = '7U7K 0DC55B H ZN0J Q9 H2X0 LZ16A ECA2DE 6A2 NUPU 67IL6EIH YVZA 5OTGC3U C3R PGW RS0 84QTV4PB EZ1 JBGJ TT1W4M5PBJ GZVLWXQG 7POU6 FMTXA N3CZ Y1Q9VZ6 9TVL CWP8KSB'\n",
    "phrase = '6 WREB W7UU QNWXS2 3KRO72Q AN1TI QZIWH G L0U7 Y17X45 OVIC2 C052W00PI60 O5Y 10R2N 4 FHC JXRGS4 DWBOL7ZUXJU EMNC3 WWBNT7 0UP GMKQ YG83H8 IT2Q Y0YBZ SQ80I5 W7SW 0K BMJ8JPM 51CK1 R08T 7SU1LYS7W6T 4JKVQF V3G UU2O1OM4 P4B 4A9DLC VI1H 4 HMP57 Q6G3 4QADIG FRJ 0MVL EPSM CS N9IZEMA GSRWUPBYB FD29 YI3PY N31W X88NS 773EW4Q4 LSW'\n",
    "Fs = 8000\n",
    "morse_gen = MorseGen.Morse()\n",
    "samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "n_prev = int((samples_per_dit/128)*12) + 1 # number of samples to look back is slightly more than a dit-dah and a word space (2+3+7=12)\n",
    "print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "label_df = morse_gen.encode_df_decim(phrase, samples_per_dit, 128)\n",
    "print(label_df.shape)\n",
    "plt.figure(figsize=(50,5))\n",
    "x = 0\n",
    "y = 1500\n",
    "plt.plot(label_df[x:y].env*0.9 + 0.0, label='env')\n",
    "plt.plot(label_df[x:y].dit*0.9 + 1.0, label='dit')\n",
    "plt.plot(label_df[x:y].dah*0.9 + 2.0, label='dah')\n",
    "plt.plot(label_df[x:y].ele*0.9 + 3.0, label='ele')\n",
    "plt.plot(label_df[x:y].chr*0.9 + 4.0, label='chr')\n",
    "plt.plot(label_df[x:y].wrd*0.9 + 5.0, label='wrd')\n",
    "plt.title(\"labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Envelope\n",
    "\n",
    "The SNR must be calculated in the FFT bin bandwidth. In the original `RNN-Morse-pytorch` notebook the bandwidth is 4 kHz / 256 = 15,625 Hz and SNR is 3 dB. Theoretically you would apply the FFT ratio to the original SNR but this does not work in practice. You have to take a much lower SNR to obtain a similar envelope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# from scipy.signal import butter,filtfilt\n",
    "\n",
    "# def butter_lowpass_filter(data, cutoff, order):\n",
    "#     # Get the filter coefficients \n",
    "#     b, a = butter(order, cutoff, btype='low', analog=False)\n",
    "#     y = filtfilt(b, a, data)\n",
    "#     return y\n",
    "\n",
    "SNR_dB = -23\n",
    "SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "SNR_linear *= 256 # Apply original FFT\n",
    "print(f'Resulting SNR for original {SNR_dB} dB is {(10.0 * np.log10(SNR_linear)):.2f} dB')\n",
    "t = np.linspace(0, len(label_df)-1, len(label_df))\n",
    "morsecode = label_df.env\n",
    "power = morsecode.var()\n",
    "noise_power = power/SNR_linear\n",
    "noise = np.sqrt(noise_power)*np.random.normal(0, 1, len(morsecode))\n",
    "# noise = butter_lowpass_filter(raw_noise, 0.9, 3) # Noise is also filtered in the original setup from audio. This empirically simulates it\n",
    "signal = morsecode + noise\n",
    "#signal[signal < 4*np.sqrt(noise_power)] = 0 # trim around zero\n",
    "#signal[signal < 0] = 0 # trim zero\n",
    "print(len(signal))\n",
    "\n",
    "plt.figure(figsize=[25,5])\n",
    "plt.plot(signal[x:y])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,5))\n",
    "plt.plot(label_df[x:y].dit*0.9 + 0.0, label='dit')\n",
    "plt.plot(label_df[x:y].dah*0.9 + 1.0, label='dah')\n",
    "plt.plot(label_df[x:y].ele*0.9 + 2.0, label='ele')\n",
    "plt.plot(label_df[x:y].chr*0.9 + 3.0, label='chr')\n",
    "plt.plot(label_df[x:y].wrd*0.9 + 4.0, label='wrd')\n",
    "plt.plot(label_df[x:y].env*5.2, label='env', linestyle='--')\n",
    "plt.title(\"labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "\n",
    "Let's create the model now so we have an idea of its inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MorseEnvLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "    \n",
    "class MorseEnvLSTM2(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM stack\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=2, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(2, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(2, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "        \n",
    "class MorseEnvNoHLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Do not keep hidden cell\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1), (h0, c0))\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "class MorseEnvBiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Attempt Bidirectional LSTM: does not work\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_size=12, num_layers=1, num_classes=6):\n",
    "        super(MorseEnvBiLSTM, self).__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x.view(len(x), 1, -1), (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model instance and print the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hidden layers:\n",
    "# 4: good at reconstructing signal, some post-processing necessary for dit/dah, word silence is weak and undistinguishable from character silence \n",
    "# 5: fairly good at reconstructing signal, but word space sense is lost\n",
    "# 6: more contrast on all signals and word space sense is good but a spike appears in the silence in predicted envelope\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "morse_env_model = MorseEnvLSTM(device, hidden_layer_size=6).to(device) # This is the only way to get things work properly with device\n",
    "morse_env_loss_function = nn.MSELoss()\n",
    "morse_env_optimizer = torch.optim.Adam(morse_env_model.parameters(), lr=0.001)\n",
    "\n",
    "print(morse_env_model)\n",
    "print(morse_env_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu\n",
    "for m in morse_env_model.parameters():\n",
    "    print(m.shape, m.device)\n",
    "#X_t = torch.rand((48, 1))\n",
    "X_t = torch.tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341, -1.0000, -0.9385])\n",
    "X_t = X_t.cuda()\n",
    "print(X_t)\n",
    "morse_env_model(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "channels=10\n",
    "H=n_prev\n",
    "W=1\n",
    "torchinfo.summary(morse_env_model, input_size=(channels, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training data\n",
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = signal.to_numpy()\n",
    "sig /= max(sig)\n",
    "labels = label_df\n",
    "labels = labels.truncate(after=len(sig)-1, copy=False)\n",
    "print(type(labels), type(sig), labels.shape, sig.shape, len(labels), len(sig))\n",
    "plt.figure(figsize=[25,5])\n",
    "plt.plot(sig[x:y])\n",
    "plt.title(\"Signal (X)\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(sig[x:y]*0.9 + 0.0, label=\"sig_X\")\n",
    "plt.plot(labels[x:y].env*0.9 + 1.0, label=\"env_y\")\n",
    "plt.plot(labels[x:y].dit*0.9 + 2.0, label=\"dit\")\n",
    "plt.plot(labels[x:y].dah*0.9 + 3.0, label=\"dah\")\n",
    "plt.plot(labels[x:y].ele*0.9 + 4.0, label=\"ele\")\n",
    "plt.plot(labels[x:y].chr*0.9 + 5.0, label=\"chr\")\n",
    "plt.plot(labels[x:y].wrd*0.9 + 6.0, label=\"wrd\")\n",
    "plt.title(\"image line and labels\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data for PyTorch \n",
    "With training and test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / test values for splitting\n",
    "test_ratio = 0.5\n",
    "n_trn = round(len(labels) * (1 - test_ratio))\n",
    "print(n_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result are distinct tensors of input tensors and output tensors directly moved to device (GPU if this is the case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_rolling_window(x, window_size, step_size=1):\n",
    "    # unfold dimension to make our rolling window\n",
    "    return x.unfold(0,window_size,step_size)\n",
    "\n",
    "X_train = pytorch_rolling_window(torch.FloatTensor(sig[:n_trn]), n_prev, 1).to(device)\n",
    "y_train = torch.FloatTensor(labels.iloc[n_prev:n_trn+1].values).to(device)\n",
    "print(\"Train shapes\", X_train.shape, y_train.shape)\n",
    "print(\"X train\\n\", X_train)\n",
    "print(\"y_train\\n\", y_train)\n",
    "print(\"train[0] shapes\", X_train[0].shape, y_train[0].shape)\n",
    "X_test = pytorch_rolling_window(torch.FloatTensor(sig[n_trn:-1]), n_prev, 1).to(device)\n",
    "y_test = torch.FloatTensor(labels.iloc[n_trn+n_prev:].values).to(device)\n",
    "print(\"Test shape\", X_test.shape, y_test.shape)\n",
    "# make sure it works\n",
    "y_pred = morse_env_model(X_train[0])\n",
    "print(\"y_pred\\n\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to CPU for visualization\n",
    "X_train_v = X_train.cpu()\n",
    "y_train_v = y_train.cpu()\n",
    "X_test_v = X_test.cpu()\n",
    "y_test_v = y_test.cpu()\n",
    "\n",
    "# Input (noisy) data for visualization\n",
    "l_train = sig[:n_trn+n_prev]\n",
    "l_test = sig[n_trn+n_prev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "b = []\n",
    "for t in range(5):\n",
    "    a.append(X_test_v[t*n_prev])\n",
    "    b.append(X_train_v[t*n_prev])\n",
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(np.concatenate((tuple(a)))*0.5, label='test')\n",
    "plt.plot(np.concatenate((tuple(b)))*0.5+0.5, label='train')\n",
    "plt.title(\"Train and test\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(5):\n",
    "    a.append(X_test_v[i*n_prev])\n",
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(np.concatenate(tuple(a)), label='X_test')\n",
    "plt.plot(l_test[:5*n_prev]+1.0, label='line')\n",
    "plt.plot(y_test_v[:5*n_prev,0]+2.0, label='y_test')\n",
    "plt.title(\"Test\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "epochs = 2\n",
    "morse_env_model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    for j in range (len(X_train)):\n",
    "        morse_env_optimizer.zero_grad()\n",
    "        if morse_env_model.__class__.__name__ in [\"MorseEnvLSTM\", \"MorseEnvLSTM2\"]:\n",
    "            morse_env_model.zero_hidden_cell() # this model needs to reset the hidden cell\n",
    "        y_pred = morse_env_model(X_train[j])\n",
    "        single_loss = morse_env_loss_function(y_pred, y_train[j])\n",
    "        single_loss.backward()\n",
    "        morse_env_optimizer.step()\n",
    "        if j % 1000 == 0:\n",
    "            print(f'   train {j}/{len(X_train)} loss: {single_loss.item():10.8f}')\n",
    "    print(f'epoch: {i+1:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'final: {i+1:3} epochs loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_sig_l = []\n",
    "p_dit_l = []\n",
    "p_dah_l = []\n",
    "p_ele_l = []\n",
    "p_chr_l = []\n",
    "p_wrd_l = []\n",
    "morse_env_model.eval()\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    with torch.no_grad():\n",
    "        pred_val = morse_env_model(X_test[i]).cpu()\n",
    "        p_sig_l.append(pred_val[0].item())\n",
    "        p_dit_l.append(pred_val[1].item())\n",
    "        p_dah_l.append(pred_val[2].item())\n",
    "        p_ele_l.append(pred_val[3].item())\n",
    "        p_chr_l.append(pred_val[4].item())\n",
    "        p_wrd_l.append(pred_val[5].item())\n",
    "        \n",
    "p_sig = np.array(p_sig_l)\n",
    "p_dit = np.array(p_dit_l)\n",
    "p_dah = np.array(p_dah_l)\n",
    "p_ele = np.array(p_ele_l)\n",
    "p_chr = np.array(p_chr_l)\n",
    "p_wrd = np.array(p_wrd_l)\n",
    "\n",
    "# trim negative values\n",
    "p_sig[p_sig < 0] = 0\n",
    "p_dit[p_dit < 0] = 0\n",
    "p_dah[p_dah < 0] = 0\n",
    "p_ele[p_ele < 0] = 0\n",
    "p_chr[p_chr < 0] = 0\n",
    "p_wrd[p_wrd < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,7))\n",
    "plt.plot(y_test_v[:y,0]*0.9, label=\"y0\")\n",
    "plt.plot(p_sig[:y]*0.9 + 1.0, label=\"sig\")\n",
    "plt.plot(p_dit[:y]*0.9 + 2.0, label=\"dit\")\n",
    "plt.plot(p_dah[:y]*0.9 + 3.0, label=\"dah\")\n",
    "plt.plot(p_ele[:y]*0.9 + 4.0, label=\"ele\")\n",
    "plt.plot(p_chr[:y]*0.9 + 5.0, label=\"chr\")\n",
    "plt.plot(p_wrd[:y]*0.9 + 6.0, label=\"wrd\")\n",
    "plt.title(\"Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('img/pred.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = p_sig[:y]\n",
    "sig = (sig - min(sig)) / (max(sig) - min(sig))\n",
    "#mod = p_dit[:y] + p_dah[:y] - 3.0 * (p_ele[:y] + p_chr[:y] + p_wrd[:y])\n",
    "mod = p_sig[:y] + p_dah[:y] - p_dit[:y]\n",
    "mod = (mod - min(mod)) / (max(mod) - min(mod))\n",
    "mod[mod > 0.5] = 0.5\n",
    "mod *= 2.0\n",
    "mor = y_test_v[:y,0]\n",
    "mor = (mor - min(mor)) / (max(mor) - min(mor))\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(sig, label=\"sig\")\n",
    "plt.title(\"predicted signal modulation\")\n",
    "plt.grid()\n",
    "plt.figure(figsize=(30,3))\n",
    "plt.plot(mod, label=\"mod\")\n",
    "plt.plot(l_test[:y] + 1.0, label=\"sig\")\n",
    "plt.plot(mor*2.2, label=\"mor\", linestyle='--')\n",
    "plt.title(\"reconstructed signal modulation with 'dah' and 'dit'\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mor = y_test_v[:y,0]\n",
    "plt.figure(figsize=(25,4))\n",
    "plt.plot(p_dit[:y], label='dit')\n",
    "plt.plot(p_dah[:y], label='dah')\n",
    "plt.plot(mor*0.5 + 1.0, label='mor')\n",
    "plt.title(\"'dit' and 'dah' symbols prediction vs modulation\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(p_ele[:y], label='ele')\n",
    "plt.plot(mor, label='mor')\n",
    "plt.title(\"Element space prediction vs modulation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(p_chr[:y] ,label='chr')\n",
    "plt.plot(mor, label='mor')\n",
    "plt.title(\"Character space prediction vs modulation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(p_wrd[:y], label='wrd')\n",
    "plt.plot(mor, label='mor')\n",
    "plt.title(\"Word space prediction vs modulation\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,8))\n",
    "plt.plot(l_test[:y]*0.9, label=\"inp\")\n",
    "plt.plot(p_sig[:y]*0.9 + 1.0, label=\"sig\")\n",
    "plt.plot(p_dit[:y]*0.9 + 2.0, label=\"dit\")\n",
    "plt.plot(p_dah[:y]*0.9 + 3.0, label=\"dah\")\n",
    "plt.plot(p_ele[:y]*0.9 + 4.0, label=\"ele\")\n",
    "plt.plot(p_chr[:y]*0.9 + 5.0, label=\"chr\")\n",
    "plt.plot(p_wrd[:y]*0.9 + 6.0, label=\"wrd\")\n",
    "plt.plot(mor*7.2, label=\"mor\")\n",
    "plt.title(\"Altogether vs signal and modulation\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import scipy.special\n",
    "from scipy.io import wavfile\n",
    "\n",
    "Fcode = 600\n",
    "Fs = 8000\n",
    "noverlap = 128\n",
    "decim = 128\n",
    "emod = np.array([sp.special.expit(40*(x-0.5)) for x in sig])\n",
    "#emod = np.array([x if x > 0.7 else 0.0 for x in mod])\n",
    "emod /= max(emod)\n",
    "remod = np.array([[x]*noverlap for x in emod]).flatten()\n",
    "wt = (Fcode / Fs)*2*np.pi\n",
    "tone = np.sin(np.arange(len(remod))*wt)\n",
    "wavfile.write('audio/re.wav', Fs, tone*remod)\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.plot(tone*remod)\n",
    "plt.title(\"reconstructed signal\")\n",
    "plt.grid()\n",
    "# .4QTV4PB EZ1 JBGJ TT1W4M...\n",
    "# 7U7K 0DC55B H ZN0J Q9 H2X0 LZ16A ECA2DE 6A2 NUPU 67IL6EIH YVZA 5OTGC3U C3R PGW RS0 84QTV4PB EZ1 JBGJ TT1W4M5PBJ GZVLWXQG 7POU6 FMTXA N3CZ Y1Q9VZ6 9TVL CWP8KSB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omod = l_test[:y]\n",
    "omod / max(omod)\n",
    "orig_mod = np.array([[x]*decim for x in omod]).flatten()\n",
    "wavfile.write('audio/or.wav', Fs, tone*orig_mod)\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.plot(tone*orig_mod)\n",
    "plt.title(\"original filtered signal\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#phrase = '01234 6789 QUICK BROWN FOX 01234 6789 QUICK BROWN FOX01234 6789 QUICK BROWN FOX01234 6789 QUICK BROWN FOX01234 6789 QUICK BROWN FOX 01234 6789 QUICK BROWN FOX'\n",
    "#phrase = '7U7K 0DC55B H ZN0J Q9 H2X0 LZ16A ECA2DE 6A2 NUPU 67IL6EIH YVZA 5OTGC3U C3R PGW RS0 84QTV4PB EZ1 JBGJ TT1W4M5PBJ GZVLWXQG 7POU6 FMTXA N3CZ Y1Q9VZ6 9TVL CWP8KSB'\n",
    "phrase = 'VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F4EXB VVVV DE F'\n",
    "Fs = 8000\n",
    "morse_gen = MorseGen.Morse()\n",
    "samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "n_prev = int((samples_per_dit/128)*12) + 1 # number of samples to look back is slightly more than a dit-dah and a word space (2+3+7=12)\n",
    "print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "label_df = morse_gen.encode_df_decim(phrase, samples_per_dit, 128)\n",
    "print(label_df.shape)\n",
    "plt.figure(figsize=(50,5))\n",
    "x = 0\n",
    "y = 1500\n",
    "plt.plot(label_df[x:y].env*0.9 + 0.0, label='env')\n",
    "plt.plot(label_df[x:y].dit*0.9 + 1.0, label='dit')\n",
    "plt.plot(label_df[x:y].dah*0.9 + 2.0, label='dah')\n",
    "plt.plot(label_df[x:y].ele*0.9 + 3.0, label='ele')\n",
    "plt.plot(label_df[x:y].chr*0.9 + 4.0, label='chr')\n",
    "plt.plot(label_df[x:y].wrd*0.9 + 5.0, label='wrd')\n",
    "plt.title(\"labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_dB = -23\n",
    "SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "SNR_linear *= 256 # Apply original FFT\n",
    "print(f'Resulting SNR for original {SNR_dB} dB is {(10.0 * np.log10(SNR_linear)):.2f} dB')\n",
    "t = np.linspace(0, len(label_df)-1, len(label_df))\n",
    "morsecode = label_df.env\n",
    "power = morsecode.var()\n",
    "noise_power = power/SNR_linear\n",
    "noise = np.sqrt(noise_power)*np.random.normal(0, 1, len(morsecode))\n",
    "#noise = butter_lowpass_filter(raw_noise, 0.9, 3) # Noise is also filtered in the original setup from audio. This empirically simulates it\n",
    "signal = morsecode + noise\n",
    "#signal[signal < 4*np.sqrt(noise_power)] = 0 # trim around zero\n",
    "signal[signal < 0] = 0 # trim zero\n",
    "print(len(signal))\n",
    "\n",
    "plt.figure(figsize=[25,5])\n",
    "plt.plot(signal[x:y])\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training data (new prediction)\n",
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = signal.to_numpy()\n",
    "sig /= max(sig)\n",
    "labels = label_df\n",
    "labels = labels.truncate(after=len(sig)-1, copy=False)\n",
    "print(type(labels), type(sig), labels.shape, sig.shape, len(labels), len(sig))\n",
    "plt.figure(figsize=[25,5])\n",
    "plt.plot(sig[x:y])\n",
    "plt.title(\"Signal (X)\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(50,6))\n",
    "plt.plot(sig[x:y]*0.9 + 0.0, label=\"sig_X\")\n",
    "plt.plot(labels[x:y].env*0.9 + 1.0, label=\"env_y\")\n",
    "plt.plot(labels[x:y].dit*0.9 + 2.0, label=\"dit\")\n",
    "plt.plot(labels[x:y].dah*0.9 + 3.0, label=\"dah\")\n",
    "plt.plot(labels[x:y].ele*0.9 + 4.0, label=\"ele\")\n",
    "plt.plot(labels[x:y].chr*0.9 + 5.0, label=\"chr\")\n",
    "plt.plot(labels[x:y].wrd*0.9 + 6.0, label=\"wrd\")\n",
    "plt.title(\"image line and labels\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format new data for PyTorch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse optimized formatting for X pnly\n",
    "X_train = pytorch_rolling_window(torch.FloatTensor(sig[:n_trn]), n_prev, 1).to(device)\n",
    "y_train = torch.FloatTensor(labels.iloc[n_prev:n_trn+1].values).to(device)\n",
    "X_test = pytorch_rolling_window(torch.FloatTensor(sig[n_trn:-1]), n_prev, 1).to(device)\n",
    "y_test = torch.FloatTensor(labels.iloc[n_trn+n_prev:].values).to(device)\n",
    "# make sure it works\n",
    "y_pred = morse_env_model(X_train[0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to CPU for visualization\n",
    "X_train_v = X_train.cpu()\n",
    "y_train_v = y_train.cpu()\n",
    "X_test_v = X_test.cpu()\n",
    "y_test_v = y_test.cpu()\n",
    "\n",
    "# Input (noisy) data for visualization\n",
    "l_train = sig[:n_trn+n_prev]\n",
    "l_test = sig[n_trn+n_prev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "b = []\n",
    "for t in range(5):\n",
    "    a.append(X_test_v[t*n_prev])\n",
    "    b.append(X_train_v[t*n_prev])\n",
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(np.concatenate((tuple(a)))*0.5, label='test')\n",
    "plt.plot(np.concatenate((tuple(b)))*0.5+0.5, label='train')\n",
    "plt.title(\"Train and test\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(5):\n",
    "    a.append(X_test_v[i*n_prev])\n",
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(np.concatenate(tuple(a)), label='X_test')\n",
    "plt.plot(l_test[:5*n_prev]+1.0, label='line')\n",
    "plt.plot(y_test_v[:5*n_prev,0]+2.0, label='y_test')\n",
    "plt.title(\"Test\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict (new data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_sig_l = []\n",
    "p_dit_l = []\n",
    "p_dah_l = []\n",
    "p_ele_l = []\n",
    "p_chr_l = []\n",
    "p_wrd_l = []\n",
    "morse_env_model.eval()\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    with torch.no_grad():\n",
    "        pred_val = morse_env_model(X_test[i]).cpu()\n",
    "        p_sig_l.append(pred_val[0].item())\n",
    "        p_dit_l.append(pred_val[1].item())\n",
    "        p_dah_l.append(pred_val[2].item())\n",
    "        p_ele_l.append(pred_val[3].item())\n",
    "        p_chr_l.append(pred_val[4].item())\n",
    "        p_wrd_l.append(pred_val[5].item())\n",
    "        \n",
    "p_sig = np.array(p_sig_l)\n",
    "p_dit = np.array(p_dit_l)\n",
    "p_dah = np.array(p_dah_l)\n",
    "p_ele = np.array(p_ele_l)\n",
    "p_chr = np.array(p_chr_l)\n",
    "p_wrd = np.array(p_wrd_l)\n",
    "\n",
    "# trim negative values\n",
    "p_sig[p_sig < 0] = 0\n",
    "p_dit[p_dit < 0] = 0\n",
    "p_dah[p_dah < 0] = 0\n",
    "p_ele[p_ele < 0] = 0\n",
    "p_chr[p_chr < 0] = 0\n",
    "p_wrd[p_wrd < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,7))\n",
    "plt.plot(y_test_v[:y,0]*0.9, label=\"y0\")\n",
    "plt.plot(p_sig[:y]*0.9 + 1.0, label=\"sig\")\n",
    "plt.plot(p_dit[:y]*0.9 + 2.0, label=\"dit\")\n",
    "plt.plot(p_dah[:y]*0.9 + 3.0, label=\"dah\")\n",
    "plt.plot(p_ele[:y]*0.9 + 4.0, label=\"ele\")\n",
    "plt.plot(p_chr[:y]*0.9 + 5.0, label=\"chr\")\n",
    "plt.plot(p_wrd[:y]*0.9 + 6.0, label=\"wrd\")\n",
    "plt.title(\"Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = p_sig[:y]\n",
    "sig = (sig - min(sig)) / (max(sig) - min(sig))\n",
    "\n",
    "#mod = 1.0 - (p_ele[:y] + p_chr[:y] + p_wrd[:y])\n",
    "#mod = 0.9*p_sig[:y] - 0.3*(p_ele[:y] + p_chr[:y] + p_wrd[:y])\n",
    "#mod = 0.9 - 0.3*(p_ele[:y] + p_chr[:y] + p_wrd[:y])\n",
    "#mod = (mod - min(mod)) / (max(mod) - min(mod))\n",
    "mod = p_sig[:y] - 0.5*(p_chr[:y] + p_wrd[:y])\n",
    "mod[mod < 0] = 0\n",
    "mod = (mod - min(mod)) / (max(mod) - min(mod))\n",
    "\n",
    "mor = y_test_v[:y,0]\n",
    "mor = (mor - min(mor)) / (max(mor) - min(mor))\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(sig, label=\"sig\")\n",
    "plt.title(\"predicted signal modulation\")\n",
    "plt.grid()\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(mod*0.6+0.4, label=\"mod\")\n",
    "plt.plot(mor*0.3, label=\"mor\")\n",
    "plt.plot(l_test[:y]*0.3, label=\"sig\")\n",
    "plt.title(\"reconstructed signal modulation with 'dah' and 'dit'\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "#omod = np.array([sp.special.expit(12*(x-0.3)) for x in l_test[:y]])\n",
    "#omod = np.array([sp.special.expit(20*(x-0.18)) for x in l_test[:y]])\n",
    "omod = l_test[:y]\n",
    "orig_mod = np.array([[x]*decim for x in omod]).flatten()\n",
    "orig_mod /= max(orig_mod)\n",
    "wt = (Fcode / Fs)*2*np.pi\n",
    "tone = np.sin(np.arange(len(orig_mod))*wt)\n",
    "wavfile.write('audio/or1.wav', Fs, tone*orig_mod)\n",
    "ref_mod = np.array([[x]*decim for x in mor]).flatten()\n",
    "plt.figure(figsize=(50,5))\n",
    "plt.plot(tone*orig_mod, label='mod')\n",
    "plt.plot(ref_mod*1.2, label='mor')\n",
    "plt.title(\"original filtered signal\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "# def modscale(x):\n",
    "#     return sp.special.expit(20*(x-0.28))\n",
    "    \n",
    "#emod = np.array([sp.special.expit(20*(x-0.25)) for x in mod])\n",
    "emod = mod\n",
    "emod /= max(emod)\n",
    "#emod = modn\n",
    "remod = np.array([[x]*decim for x in emod]).flatten()\n",
    "remor = np.array([[x]*decim for x in mor]).flatten()\n",
    "wt = (Fcode / Fs)*2*np.pi\n",
    "tone = np.sin(np.arange(len(remod))*wt)\n",
    "wavfile.write('audio/re1.wav', Fs, tone*remod)\n",
    "plt.figure(figsize=(50,5))\n",
    "plt.plot(tone*remod, label='filt')\n",
    "plt.plot(remor*1.2, label='omod')\n",
    "plt.title(\"reconstructed signal\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
