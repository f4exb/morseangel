{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model with noisy signal - PyTorch version\n",
    "\n",
    "This notebook is based on Mauri AG1LE's work back in 2015 that can be found on Github [here](https://github.com/ag1le/RNN-Morse). From an audio signal generated at 8 kHz sample rate (thus in 4 kHz bandwidth) it attempts to recognize Morse code distinctive features in the signal that is:\n",
    "\n",
    "  - The envelope\n",
    "  - The \"dit\"\n",
    "  - The \"dah\"\n",
    "  - The element separator at the end of a \"dit\" or a \"dah\"\n",
    "  - The character separator\n",
    "  - The word separator\n",
    "  \n",
    "It trains a LSTM based recurrent neural network (RNN) on a slightly noisy signal (a few dB SNR in 4 kHz bandwidth) in an encoder-decoder fashion. The envelope of the signal is taken as input as a time series of floating point values and the labels are also time series of the 6 signals described above.\n",
    "\n",
    "It then attempts prediction on a much noisier signal of the same test data to see how it can perform in retrieving the 6 predicted signals and reformat the original envelope.\n",
    "\n",
    "This is the PyTorch version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sounddevice torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo apt-get install libportaudio2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate annotated raw signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MorseGen\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "#phrase = '01234 6789 QUICK BROWN FOX 01234 6789 QUICK BROWN FOX01234 6789 QUICK BROWN FOX01234 6789 QUICK BROWN FOX01234 6789 QUICK BROWN FOX 01234 6789 QUICK BROWN FOX'\n",
    "#phrase = '7U7K 0DC55B H ZN0J Q9 H2X0 LZ16A ECA2DE 6A2 NUPU 67IL6EIH YVZA 5OTGC3U C3R PGW RS0 84QTV4PB EZ1 JBGJ TT1W4M5PBJ GZVLWXQG 7POU6 FMTXA N3CZ Y1Q9VZ6 9TVL CWP8KSB'\n",
    "phrase = '6 WREB W7UU QNWXS2 3KRO72Q AN1TI QZIWH G L0U7 Y17X45 OVIC2 C052W00PI60 O5Y 10R2N 4 FHC JXRGS4 DWBOL7ZUXJU EMNC3 WWBNT7 0UP GMKQ YG83H8 IT2Q Y0YBZ SQ80I5 W7SW 0K BMJ8JPM 51CK1 R08T 7SU1LYS7W6T 4JKVQF V3G UU2O1OM4 P4B 4A9DLC VI1H 4 HMP57 Q6G3 4QADIG FRJ 0MVL EPSM CS N9IZEMA GSRWUPBYB FD29 YI3PY N31W X88NS 773EW4Q4 LSW'\n",
    "Fs = 8000\n",
    "morse_gen = MorseGen.Morse()\n",
    "samples_per_dit = morse_gen.nb_samples_per_dit(Fs, 13)\n",
    "n_prev = int((samples_per_dit/128)*12) + 1 # number of samples to look back is slightly more than a dit-dah and a word space (2+3+7=12)\n",
    "print(f'Samples per dit at {Fs} Hz is {samples_per_dit}. Decimation is {samples_per_dit/128:.2f}. Look back is {n_prev}.')\n",
    "label_df = morse_gen.encode_df(phrase, samples_per_dit)\n",
    "# keep just the envelope\n",
    "label_df.drop(columns=['dit','dah', 'ele', 'chr', 'wrd'], inplace=True)\n",
    "print(label_df.shape)\n",
    "plt.figure(figsize=(50,5))\n",
    "x = 210000\n",
    "y = 300000\n",
    "plt.plot(label_df[x:y].env*0.9 + 0.0, label='env')\n",
    "plt.title(\"labels\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "Fc = 600\n",
    "SNR_dB = -3\n",
    "SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "t = np.linspace(0, len(label_df)-1, len(label_df))\n",
    "cw = np.sin((Fc/Fs)*2*np.pi*t)\n",
    "morsecode = cw * label_df.env\n",
    "power = morsecode.var()\n",
    "noise_power = power/SNR_linear\n",
    "noise = np.sqrt(noise_power)*np.random.normal(0, 1, len(morsecode))\n",
    "signal = morsecode + noise\n",
    "print(len(signal))\n",
    "\n",
    "plt.figure(figsize=[25,5])\n",
    "plt.plot(signal[210000:300000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Envelope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,2))\n",
    "plt.plot(label_df[x:y].env)\n",
    "plt.title(\"envelope\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,10))\n",
    "plt.ylabel(\"Frequency (Hz)\")\n",
    "plt.xlabel(\"Time (seconds)\")\n",
    "_ = plt.specgram(signal[0:30*Fs], NFFT=256, Fs=Fs, Fc=0, mode='magnitude', noverlap=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate final annotated data\n",
    "### Find peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MorseDSP\n",
    "\n",
    "maxtab, f, s = MorseDSP.find_peak(Fs, signal)\n",
    "tone = maxtab[0,0]\n",
    "plt.title(\"Morse signal peak found at {} Hz\".format(tone))\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Amplitude (log)\")\n",
    "plt.yscale('log')\n",
    "_ = plt.plot(f[0:int(len(f)/2-1)], abs(s[0:int(len(s)/2-1)]),'g-')\n",
    "_ = plt.scatter(maxtab[:,0], maxtab[:,1], c='r') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nside_bins = 1\n",
    "nfft = 256\n",
    "f, t, img, noverlap = MorseDSP.specimg(Fs, signal, None, None, tone, nfft, nside_bins)\n",
    "decim = nfft - noverlap\n",
    "print(type(signal), signal.shape)\n",
    "print(type(f), f.shape)\n",
    "print(type(t), t.shape, max(t))\n",
    "print(type(img), img.shape)\n",
    "print(noverlap, len(signal)//noverlap, decim)\n",
    "# Show first 25 seconds at most\n",
    "rmax = 25 / max(t) if max(t) > 25 else 25\n",
    "imax = int(rmax*len(t))\n",
    "t1 = t[:imax]\n",
    "img1 = img[:,:imax]\n",
    "plt.figure(figsize=(30,3))\n",
    "plt.pcolormesh(t1, f, img1, shading='flat', cmap=plt.get_cmap('binary'))\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate spectral line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,3))\n",
    "plt.plot(img[nside_bins-1][:1500], label=\"-1\")\n",
    "plt.plot(img[nside_bins][:1500], label=\"0\")\n",
    "plt.plot(img[nside_bins+1][:1500], label=\"+1\")\n",
    "plt.legend()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_line = np.sum(img, axis=0)\n",
    "img_line /= max(img_line)\n",
    "print(img_line.shape)\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.plot(img_line[:1500], label=\"lin\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model\n",
    "\n",
    "Let's create the model now so we have an idea of its inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MorseEnvLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Initial implementation\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(1, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(1, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(1, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "    \n",
    "class MorseEnvLSTM2(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTM stack\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size, num_layers=2, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "        self.hidden_cell = (torch.zeros(2, 1, self.hidden_layer_size).to(self.device),\n",
    "                            torch.zeros(2, 1, self.hidden_layer_size).to(self.device))\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "    def zero_hidden_cell(self):\n",
    "        self.hidden_cell = (\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device),\n",
    "            torch.zeros(2, 1, self.hidden_layer_size).to(device)\n",
    "        )        \n",
    "        \n",
    "class MorseEnvNoHLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Do not keep hidden cell\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_layer_size=8, output_size=6):\n",
    "        super().__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        h0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_layer_size).to(self.device)\n",
    "        lstm_out, _ = self.lstm(input_seq.view(len(input_seq), 1, -1), (h0, c0))\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "    \n",
    "class MorseEnvBiLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Attempt Bidirectional LSTM: does not work\n",
    "    \"\"\"\n",
    "    def __init__(self, device, input_size=1, hidden_size=12, num_layers=1, num_classes=6):\n",
    "        super(MorseEnvBiLSTM, self).__init__()\n",
    "        self.device = device # This is the only way to get things work properly with device\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x.view(len(x), 1, -1), (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        # Decode the hidden state of the last time step\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out[-1]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model instance and print the details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#morse_env_model = MorseEnvLSTM(device, hidden_layer_size=5, output_size=1).to(device) # This is the only way to get things work properly with device\n",
    "morse_env_model = MorseEnvLSTM2(device, hidden_layer_size=5, output_size=1).to(device)\n",
    "morse_env_loss_function = nn.MSELoss()\n",
    "morse_env_optimizer = torch.optim.Adam(morse_env_model.parameters(), lr=0.001)\n",
    "\n",
    "print(morse_env_model)\n",
    "print(morse_env_model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cpu\n",
    "for m in morse_env_model.parameters():\n",
    "    print(m.shape, m.device)\n",
    "#X_t = torch.rand((48, 1))\n",
    "X_t = torch.tensor([-0.9648, -0.9385, -0.8769, -0.8901, -0.9253, -0.8637, -0.8066, -0.8066, -0.8593, -0.9341, -1.0000, -0.9385])\n",
    "X_t = X_t.cuda()\n",
    "print(X_t)\n",
    "morse_env_model(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchinfo\n",
    "channels=10\n",
    "H=n_prev\n",
    "W=1\n",
    "torchinfo.summary(morse_env_model, input_size=(channels, H, W))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training data\n",
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = img_line\n",
    "sig /= max(img_line)\n",
    "labels = label_df[::decim] # decimate labels by spectrum decimation\n",
    "labels.reset_index(drop=True, inplace=True)\n",
    "labels = labels.truncate(after=len(sig)-1, copy=False)\n",
    "print(type(labels), type(sig), labels.shape, sig.shape, len(labels), len(sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "y = imax\n",
    "print(x, y)\n",
    "plt.figure(figsize=(30,2))\n",
    "plt.plot(sig[x:y]*0.9 + 0.0, label=\"sig_X\")\n",
    "plt.plot(labels[x:y].env*0.9 + 1.0, label=\"env_y\")\n",
    "plt.title(\"image line and labels\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format data for PyTorch \n",
    "With training and test data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values for train / test split\n",
    "test_ratio = 0.5\n",
    "n_trn = round(len(labels) * (1 - test_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_rolling_window(x, window_size, step_size=1):\n",
    "    # unfold dimension to make our rolling window\n",
    "    return x.unfold(0,window_size,step_size)\n",
    "\n",
    "X_train = pytorch_rolling_window(torch.FloatTensor(sig[:n_trn]), n_prev, 1).to(device)\n",
    "y_train = torch.FloatTensor(labels.iloc[n_prev:n_trn+1].values).to(device)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_train)\n",
    "print(y_train)\n",
    "print(X_train[0].shape, y_train[0].shape)\n",
    "X_test = pytorch_rolling_window(torch.FloatTensor(sig[n_trn:-1]), n_prev, 1).to(device)\n",
    "y_test = torch.FloatTensor(labels.iloc[n_trn+n_prev:].values).to(device)\n",
    "print(X_test.shape, y_test.shape)\n",
    "# make sure it works\n",
    "y_pred = morse_env_model(X_train[0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to CPU for visualization\n",
    "X_train_v = X_train.cpu()\n",
    "y_train_v = y_train.cpu()\n",
    "X_test_v = X_test.cpu()\n",
    "y_test_v = y_test.cpu()\n",
    "\n",
    "# Input (noisy) data for visualization\n",
    "l_train = sig[:n_trn+n_prev]\n",
    "l_test = sig[n_trn+n_prev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "b = []\n",
    "for t in range(5):\n",
    "    a.append(X_test_v[t*n_prev])\n",
    "    b.append(X_train_v[t*n_prev])\n",
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(np.concatenate((tuple(a)))*0.5, label='test')\n",
    "plt.plot(np.concatenate((tuple(b)))*0.5+0.5, label='train')\n",
    "plt.title(\"Train and test\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(5):\n",
    "    a.append(X_test_v[i*n_prev])\n",
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(np.concatenate(tuple(a)), label='X_test')\n",
    "plt.plot(l_test[:5*n_prev]+1.0, label='line')\n",
    "plt.plot(y_test_v[:5*n_prev,0]+2.0, label='y_test')\n",
    "plt.title(\"Test\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "morse_env_model.load_state_dict(torch.load('models/morse_env_model_lstm2_02'))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "epochs = 2\n",
    "morse_env_model.train()\n",
    "\n",
    "for i in range(epochs):\n",
    "    for j in range (len(X_train)):\n",
    "        morse_env_optimizer.zero_grad()\n",
    "        if morse_env_model.__class__.__name__ == \"MorseEnvLSTM\":\n",
    "            morse_env_model.zero_hidden_cell() # this model needs to reset the hidden cell        \n",
    "        y_pred = morse_env_model(X_train[j])\n",
    "        single_loss = morse_env_loss_function(y_pred, y_train[j])\n",
    "        single_loss.backward()\n",
    "        morse_env_optimizer.step()\n",
    "        if j % 1000 == 0:\n",
    "            print(f'   train {j}/{len(X_train)} loss: {single_loss.item():10.8f}')\n",
    "    print(f'epoch: {i+1:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "print(f'final: {i+1:3} epochs loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_sig_l = []\n",
    "morse_env_model.eval()\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    with torch.no_grad():\n",
    "        pred_val = morse_env_model(X_test[i]).cpu()\n",
    "        p_sig_l.append(pred_val[0].item())\n",
    "        \n",
    "p_sig = np.array(p_sig_l)\n",
    "\n",
    "# trim negative values\n",
    "p_sig[p_sig < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,2))\n",
    "plt.plot(y_test_v[:y,0]*0.9, label=\"y0\")\n",
    "plt.plot(p_sig[:y]*0.9 + 1.0, label=\"sig\")\n",
    "plt.title(\"Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('img/pred.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = p_sig[:y]\n",
    "sig = (sig - min(sig)) / (max(sig) - min(sig))\n",
    "mor = y_test_v[:y,0]\n",
    "mor = (mor - min(mor)) / (max(mor) - min(mor))\n",
    "plt.figure(figsize=(30,5))\n",
    "plt.plot(sig, label=\"sig\")\n",
    "plt.plot(l_test[:y] + 1.0, label=\"inp\")\n",
    "plt.title(\"predicted signal modulation\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "\n",
    "Fcode = 600\n",
    "Fs = 8000\n",
    "emod = sig\n",
    "emod /= max(emod)\n",
    "remod = np.array([[x]*noverlap for x in emod]).flatten()\n",
    "wt = (Fcode / Fs)*2*np.pi\n",
    "tone = np.sin(np.arange(len(remod))*wt)\n",
    "wavfile.write('audio/re.wav', Fs, tone*remod)\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.plot(tone*remod)\n",
    "plt.title(\"reconstructed signal\")\n",
    "plt.grid()\n",
    "# .4QTV4PB EZ1 JBGJ TT1W4M...\n",
    "# 7U7K 0DC55B H ZN0J Q9 H2X0 LZ16A ECA2DE 6A2 NUPU 67IL6EIH YVZA 5OTGC3U C3R PGW RS0 84QTV4PB EZ1 JBGJ TT1W4M5PBJ GZVLWXQG 7POU6 FMTXA N3CZ Y1Q9VZ6 9TVL CWP8KSB'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "omod = l_test[:y]\n",
    "omod / max(omod)\n",
    "orig_mod = np.array([[x]*decim for x in omod]).flatten()\n",
    "wavfile.write('audio/or.wav', Fs, tone*orig_mod)\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.plot(tone*orig_mod)\n",
    "plt.title(\"original filtered signal\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make new predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_dB = -15\n",
    "SNR_linear = 10.0**(SNR_dB/10.0)\n",
    "noise_power = power/SNR_linear\n",
    "noise = np.sqrt(noise_power)*np.random.normal(0, 1, len(morsecode))\n",
    "signal1 = morsecode + noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find peak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxtab, f, s = MorseDSP.find_peak(Fs, signal1)\n",
    "tone = maxtab[0,0]\n",
    "plt.title(\"Morse signal peak found at {} Hz\".format(tone))\n",
    "plt.xlabel(\"Frequency (Hz)\")\n",
    "plt.ylabel(\"Amplitude (log)\")\n",
    "plt.yscale('log')\n",
    "_ = plt.plot(f[0:int(len(f)/2-1)], abs(s[0:int(len(s)/2-1)]),'g-')\n",
    "_ = plt.scatter(maxtab[:,0], maxtab[:,1], c='r') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nside_bins = 1\n",
    "nfft = 256\n",
    "f, t, img, noverlap = MorseDSP.specimg(Fs, signal1, None, None, tone, nfft, nside_bins)\n",
    "decim = nfft - noverlap\n",
    "print(type(signal1), signal1.shape)\n",
    "print(type(f), f.shape)\n",
    "print(type(t), t.shape, max(t))\n",
    "print(type(img), img.shape)\n",
    "print(noverlap, len(signal1)//noverlap, decim)\n",
    "# Show first 25 seconds at most\n",
    "rmax = 25 / max(t) if max(t) > 25 else 25\n",
    "imax = int(rmax*len(t))\n",
    "t1 = t[:imax]\n",
    "img1 = img[:,:imax]\n",
    "plt.figure(figsize=(30,3))\n",
    "plt.pcolormesh(t1, f, img1, shading='flat', cmap=plt.get_cmap('binary'))\n",
    "plt.ylabel('Frequency [Hz]')\n",
    "plt.xlabel('Time [sec]')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate spectral line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,3))\n",
    "plt.plot(img[nside_bins-1][:1500], label=\"-1\")\n",
    "plt.plot(img[nside_bins][:1500], label=\"0\")\n",
    "plt.plot(img[nside_bins+1][:1500], label=\"+1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_line = img[nside_bins] #np.sum(img, axis=0)\n",
    "img_line /= max(img_line)\n",
    "print(img_line.shape)\n",
    "plt.figure(figsize=(30,3))\n",
    "plt.plot(img_line[:1500], label=\"lin\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training data (new prediction)\n",
    "### Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = img_line\n",
    "sig /= max(img_line)\n",
    "labels = label_df[::decim] # decimate labels by spectrum decimation\n",
    "labels.reset_index(drop=True, inplace=True)\n",
    "labels = labels.truncate(after=len(sig)-1, copy=False)\n",
    "print(type(labels), type(sig), labels.shape, sig.shape, len(labels), len(sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 0\n",
    "y = imax\n",
    "print(x, y)\n",
    "plt.figure(figsize=(30,2))\n",
    "plt.plot(sig[x:y]*0.9 + 0.0, label=\"sig_X\")\n",
    "plt.plot(labels[x:y].env*0.9 + 1.0, label=\"env_y\")\n",
    "plt.title(\"image line and labels\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format new data for PyTorch \n",
    "Same labels and y but new X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse optimized formatting for X pnly\n",
    "X_train = pytorch_rolling_window(torch.FloatTensor(sig[:n_trn]), n_prev, 1).to(device)\n",
    "X_test = pytorch_rolling_window(torch.FloatTensor(sig[n_trn:-1]), n_prev, 1).to(device)\n",
    "# make sure it works\n",
    "y_pred = morse_env_model(X_train[0])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move data to CPU for visualization\n",
    "X_train_v = X_train.cpu()\n",
    "X_test_v = X_test.cpu()\n",
    "\n",
    "# Input (noisy) data for visualization\n",
    "l_train = sig[:n_trn+n_prev]\n",
    "l_test = sig[n_trn+n_prev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "b = []\n",
    "for t in range(5):\n",
    "    a.append(X_test_v[t*n_prev])\n",
    "    b.append(X_train_v[t*n_prev])\n",
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(np.concatenate((tuple(a)))*0.5, label='test')\n",
    "plt.plot(np.concatenate((tuple(b)))*0.5+0.5, label='train')\n",
    "plt.title(\"Train and test\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "for i in range(5):\n",
    "    a.append(X_test_v[i*n_prev])\n",
    "plt.figure(figsize=(25,3))\n",
    "plt.plot(np.concatenate(tuple(a)), label='X_test')\n",
    "plt.plot(l_test[:5*n_prev]+1.0, label='line')\n",
    "plt.plot(y_test_v[:5*n_prev,0]+2.0, label='y_test')\n",
    "plt.title(\"Test\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict (new data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "p_sig_l = []\n",
    "morse_env_model.eval()\n",
    "\n",
    "for i in range(len(X_test)):\n",
    "    with torch.no_grad():\n",
    "        pred_val = morse_env_model(X_test[i]).cpu()\n",
    "        p_sig_l.append(pred_val[0].item())\n",
    "        \n",
    "p_sig = np.array(p_sig_l)\n",
    "\n",
    "# trim negative values\n",
    "p_sig[p_sig < 0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,2))\n",
    "plt.plot(y_test_v[:y,0]*0.9, label=\"y0\")\n",
    "plt.plot(p_sig[:y]*0.9 + 1.0, label=\"sig\")\n",
    "plt.title(\"Predictions\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig('img/pred.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = p_sig[:y]\n",
    "sig = (sig - min(sig)) / (max(sig) - min(sig))\n",
    "mor = y_test_v[:y,0]\n",
    "mor = (mor - min(mor)) / (max(mor) - min(mor))\n",
    "plt.figure(figsize=(30,6))\n",
    "plt.plot(sig, label=\"sig\")\n",
    "plt.plot(mor*1.2, label=\"mor\")\n",
    "plt.title(\"predicted signal modulation\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "#omod = np.array([sp.special.expit(12*(x-0.3)) for x in l_test[:y]])\n",
    "omod = l_test[:y]\n",
    "orig_mod = np.array([[x]*decim for x in omod]).flatten()\n",
    "orig_mod /= max(orig_mod)\n",
    "wt = (Fcode / Fs)*2*np.pi\n",
    "tone = np.sin(np.arange(len(orig_mod))*wt)\n",
    "wavfile.write('audio/or1.wav', Fs, tone*orig_mod)\n",
    "ref_mod = np.array([[x]*decim for x in mor]).flatten()\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.plot(tone*orig_mod, label='mod')\n",
    "plt.plot(ref_mod*1.2, label='mor')\n",
    "plt.title(\"original filtered signal\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "# def modscale(x):\n",
    "#     return sp.special.expit(20*(x-0.28))\n",
    "    \n",
    "emod = sig\n",
    "# emod[emod < 0.12] = 0 # eliminate bias\n",
    "# emod = np.array([sp.special.expit(20*(x-0.15)) for x in sig])\n",
    "emod /= max(emod)\n",
    "#emod = modn\n",
    "remod = np.array([[x]*decim for x in emod]).flatten()\n",
    "remor = np.array([[x]*decim for x in mor]).flatten()\n",
    "wt = (Fcode / Fs)*2*np.pi\n",
    "tone = np.sin(np.arange(len(remod))*wt)\n",
    "wavfile.write('audio/re1.wav', Fs, tone*remod)\n",
    "plt.figure(figsize=(50,10))\n",
    "plt.plot(tone*remod, label='filt')\n",
    "plt.plot(remor*1.2, label='omod')\n",
    "plt.title(\"reconstructed signal\")\n",
    "plt.legend()\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "sx = np.linspace(0, 1, 121)\n",
    "sy = sp.special.expit(10*(sx-0.15))\n",
    "plt.plot(sx, sy)\n",
    "plt.grid()\n",
    "plt.xlabel('x')\n",
    "plt.title('expit(x)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
